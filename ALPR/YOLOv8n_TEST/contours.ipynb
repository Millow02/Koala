{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24334a8f-4445-427d-a475-7fe4b26ec2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "#from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b985b-6402-43fc-82f0-de07e6afd6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d608f-ab3d-4b64-9109-453d91b16e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "def get_img():\n",
    "    import requests\n",
    "\n",
    "    url = \"https://img03.platesmania.com/221209/m/20496102.jpg\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.google.com\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(\"img.jpg\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Image downloaded successfully!\")\n",
    "    else:\n",
    "        print(\"Failed to download image:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830817b6-59e2-46a7-9cdb-ab3a9c1e770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_with_mode(model_path, image_path, output_dir='cropped_outputs'):\n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # model_path = 'COEN490/Koala/ALPR/YOLOv8n_TEST/my_project/exp1/weights/best.pt'\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Read the image using cv2\n",
    "    # (Note: cv2 reads images in BGR format by default)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Run inference (prediction) on the image\n",
    "    # The results returned is a list of results (one per image in the batch)\n",
    "    results = model.predict(source=image_path, conf=0.25, iou=0.45)\n",
    "    \n",
    "    for result in results:\n",
    "        # The 'boxes' attribute contains the bounding boxes.\n",
    "        # The .xyxy attribute returns the bounding boxes in [x1, y1, x2, y2] format.\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()  # Convert to NumPy array if on GPU\n",
    "    \n",
    "        # Loop through each detected bounding box\n",
    "        for idx, box in enumerate(boxes):\n",
    "            # Extract coordinates and cast them to integer\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            \n",
    "            # Crop the image using the bounding box coordinates\n",
    "            # Note: image is a NumPy array with shape (height, width, channels)\n",
    "            cropped_image = image[y1:y2, x1:x2]\n",
    "            # Define a filename for the cropped image\n",
    "            output_path = os.path.join(output_dir, f'cropped_object_{idx+1}.jpg')\n",
    "            \n",
    "            # Save the cropped image using cv2.imwrite\n",
    "            cv2.imwrite(output_path, cropped_image)\n",
    "            print(f'Saved cropped image to {output_path}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ac6be-b7f2-4a27-9d90-dae3572dd6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_path = \"/speed-scratch/z_amm/COEN490/Koala/ALPR/YOLOv8n_TEST/my_project/exp1/weights/best.pt\"\n",
    "image_path = '/speed-scratch/z_amm/COEN490/Koala/ALPR/YOLOv8n_TEST/datasets/other/img.jpg'\n",
    "crop_image_with_mode(mod_path, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e44e770-a4b3-4623-b762-7a51404a14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours\n",
    "\n",
    "def upscale_img(im):\n",
    "    scale_factor = 5.0\n",
    "    new_width = int(im.shape[1] * scale_factor)\n",
    "    new_height = int(im.shape[0] * scale_factor)\n",
    "\n",
    "    # Resize the image using cubic interpolation (better quality)\n",
    "    upscaled_im = cv2.resize(im, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    return upscaled_im\n",
    "\n",
    "def find_rect(cnt_points):\n",
    "    \"\"\"\n",
    "    Returns a list of rectangles set as 4 points \n",
    "    \"\"\"\n",
    "    # first find the leftmost point out of all the contours\n",
    "    \n",
    "    biggest_rect = []\n",
    "    for cnt in cnt_points: \n",
    "        leftmost = min(cnt, key=lambda p: p[0][0]*p[0][0] + p[0][1]*p[0][1])\n",
    "        sorted_points = sorted(cnt, key=lambda p: (leftmost[0][0] - p[0][0]) * (leftmost[0][0] - p[0][0]) + (leftmost[0][1] - p[0][1]) * (leftmost[0][1] - p[0][1]), reverse=True)\n",
    "        biggest_rect.append(np.array([leftmost, *sorted_points[:3]]))\n",
    "    print(\"\\nPrinting biggest_rect:\")\n",
    "    print(biggest_rect)\n",
    "    return biggest_rect\n",
    "\n",
    "def find_contours(image_path):\n",
    "    \"\"\"\n",
    "        Finds the contours(edges) of cropped license plate\n",
    "    \"\"\"\n",
    "    directory = \"/nfs/speed-scratch/z_amm/COEN490/Koala/ALPR/YOLOv8n_TEST\"\n",
    "    os.chdir(directory)\n",
    "\n",
    "    im = cv2.imread(image_path)\n",
    "    # im = upscale_img(im)\n",
    "    assert im is not None, \"file could not be read, check with os.path.exists()\"\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(imgray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    blur = cv2.GaussianBlur(thresh,(5,5),0)\n",
    "    th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filtering contours\n",
    "    license_plate_contour = []\n",
    "    for cnt in contours:\n",
    "        # Get bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        # Define aspect ratio and size constraints\n",
    "        aspect_ratio = w / float(h)\n",
    "        if 1 < aspect_ratio < 6 and 70000 < cv2.contourArea(cnt):  \n",
    "            print(f\"\\nContour area for:\")\n",
    "            print(cv2.contourArea(cnt))\n",
    "            approx = cv2.approxPolyDP(cnt, 0.01 * cv2.arcLength(cnt, True), True)\n",
    "            # Check if it's a quadrilateral (4 corners)\n",
    "            print(\"Sides detected:\")\n",
    "\n",
    "            print(len(approx))\n",
    "\n",
    "            if 3 < len(approx) < 7:\n",
    "                print(\"Sides detected:\")\n",
    "                print(len(approx))\n",
    "                license_plate_contour.append(approx)\n",
    "                # break  # Assuming only one plate, stop searching\n",
    "\n",
    "    # for cnt in contours:\n",
    "    #     print(f\"{cv2.contourArea(cnt)}\")\n",
    "    # Draw the detected license plate\n",
    "    # if license_plate_contour is not None:\n",
    "    \n",
    "    cv2.drawContours(im, [license_plate_contour[1]], -1, (0, 255, 0), 3)\n",
    "    \n",
    "    rectangles_extracted = find_rect(license_plate_contour)\n",
    "    warp_im = None\n",
    "    for cnt in rectangles_extracted:\n",
    "        is_rect, confidence = is_rectangle(cnt)\n",
    "        print(f\"{cnt}: is Rectangle? {is_rect}, Confidence Level: {confidence}\")\n",
    "        if confidence > 20: \n",
    "            cv2.drawContours(im, [cnt], -1, (0, 255, 0), 3)\n",
    "            warp_im = straighten_image(cnt, im)\n",
    "        \n",
    "    # upscaled_image = upscale_baby(warp_im)\n",
    "    print(license_plate_contour[0])\n",
    "    \n",
    "    print(\"Before saving image:\")  \n",
    "    print(os.listdir(directory))  \n",
    "\n",
    "    cv2.imwrite(\"img_contour_out.jpg\", im)\n",
    "    cv2.imwrite(\"warp_im.jpg\", warp_im)\n",
    "    # cv2.imwrite(\"upscaled_img.jpg\", upscaled_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9bc5f6d-e24b-48f6-a418-0249452ceb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contour area for:\n",
      "77237.5\n",
      "Sides detected:\n",
      "11\n",
      "Sides detected:\n",
      "11\n",
      "\n",
      "Contour area for:\n",
      "146320.5\n",
      "Sides detected:\n",
      "22\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/speed-scratch/z_amm/COEN490/Koala/ALPR/YOLOv8n_TEST/Pipeline/test.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfind_contours\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 72\u001b[0m, in \u001b[0;36mfind_contours\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     64\u001b[0m             license_plate_contour\u001b[38;5;241m.\u001b[39mappend(approx)\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;66;03m# break  # Assuming only one plate, stop searching\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# for cnt in contours:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#     print(f\"{cv2.contourArea(cnt)}\")\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Draw the detected license plate\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# if license_plate_contour is not None:\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdrawContours(im, [\u001b[43mlicense_plate_contour\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     74\u001b[0m rectangles_extracted \u001b[38;5;241m=\u001b[39m find_rect(license_plate_contour)\n\u001b[1;32m     75\u001b[0m warp_im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "image_path = '/speed-scratch/z_amm/COEN490/Koala/ALPR/YOLOv8n_TEST/Pipeline/test.jpg'\n",
    "find_contours(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791c548b-5eaa-47b4-8e82-e6444ee40d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_rectangle(points, tolerance=5):\n",
    "    \"\"\"\n",
    "    Checks if four given points form a rectangle and returns a confidence score.\n",
    "\n",
    "    Parameters:\n",
    "        points (list of lists or np.array): Four points as [[x1, y1], [x2, y2], [x3, y3], [x4, y4]].\n",
    "        tolerance (float): Allowed deviation in degrees for right angles.\n",
    "\n",
    "    Returns:\n",
    "        (bool, float): (True if rectangle, False otherwise, confidence score in percentage)\n",
    "    \"\"\"\n",
    "    print(\"Rectangle Structure\")\n",
    "    points = restructure_array(points)\n",
    "    print(points)\n",
    "    if len(points) != 4:\n",
    "        return False, 0.0\n",
    "\n",
    "    # Convert to numpy array\n",
    "    points = np.array(points, dtype=np.float32)\n",
    "\n",
    "    # Compute centroid\n",
    "    centroid = np.mean(points, axis=0)\n",
    "\n",
    "    # Sort points by angle around centroid (ensures consistent ordering)\n",
    "    points = sorted(points, key=lambda p: np.arctan2(p[1] - centroid[1], p[0] - centroid[0]))\n",
    "\n",
    "    # Compute vectors for each side\n",
    "    vectors = [points[i] - points[(i + 1) % 4] for i in range(4)]\n",
    "\n",
    "    # Compute edge lengths\n",
    "    lengths = [np.linalg.norm(v) for v in vectors]\n",
    "\n",
    "    # Check if opposite sides are approximately equal\n",
    "    side_match = abs(lengths[0] - lengths[2]) < 1e-3 and abs(lengths[1] - lengths[3]) < 1e-3\n",
    "\n",
    "    # Compute angles using dot product\n",
    "    angles = []\n",
    "    for i in range(4):\n",
    "        v1 = vectors[i] / np.linalg.norm(vectors[i])  # Normalize\n",
    "        v2 = vectors[(i + 1) % 4] / np.linalg.norm(vectors[(i + 1) % 4])\n",
    "        dot_product = np.dot(v1, v2)\n",
    "        angle = np.arccos(np.clip(dot_product, -1.0, 1.0)) * (180 / np.pi)\n",
    "        angles.append(angle)\n",
    "\n",
    "    # Check if all angles are approximately 90 degrees\n",
    "    angle_match = all(abs(angle - 90) < tolerance for angle in angles)\n",
    "\n",
    "    # Compute confidence score (100% if all angles are exactly 90)\n",
    "    confidence = 100 - (sum(abs(angle - 90) for angle in angles) / 4)\n",
    "\n",
    "    return side_match and angle_match, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465b8bd-21ab-4229-9f23-c7fda1ca4586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points = [[0, 0], [4, 0], [4, 3], [0, 3]]  # A perfect rectangle\n",
    "is_rect, confidence = is_rectangle(points)\n",
    "print(f\"Is Rectangle: {is_rect}, Confidence: {confidence:.2f}%\")\n",
    "\n",
    "points = [[3, 3], [4, 0], [3.9, 3], [0, 3]]  # Slight distortion\n",
    "is_rect, confidence = is_rectangle(points)\n",
    "print(f\"Is Rectangle: {is_rect}, Confidence: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5552e4cd-f749-4a2a-b195-35d9f0a5ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_array(arr):\n",
    "    \"\"\"\n",
    "    Takes an indivitual set of points and returns the correct format required for the rectangle detector\n",
    "    \"\"\"\n",
    "    return [point[0].tolist() for point in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41c34f29-40f1-4e8d-b12b-43889be7c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def straighten_image(src_pts, image):\n",
    "    \"\"\"\n",
    "    Last step: \n",
    "    \n",
    "    \"\"\"\n",
    "    src_pts = np.array(restructure_array(src_pts))\n",
    "    src_pts = src_pts[[0,3,1,2]]\n",
    "    print(src_pts)\n",
    "    # Define four destination points (where the corners should be mapped)\n",
    "    dst_pts = np.array([[0, 0], [0, 200], [200, 200], [200, 0]], dtype=np.float32)\n",
    "    \n",
    "    # Compute the homography matrix\n",
    "    H, _ = cv2.findHomography(src_pts, dst_pts)\n",
    "    \n",
    "    # Get the size of the output image\n",
    "    height, width = 200, 200  # Set the desired output size\n",
    "    \n",
    "    # Apply perspective transformation (warp the image)\n",
    "    warped_image = cv2.warpPerspective(image, H, (width, height))\n",
    "    return warped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93586d01-76b3-4c87-94fa-6dd402599bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_baby(image):\n",
    "    \"\"\"\n",
    "    Upscale the image using ESR-GAN Lite\n",
    "    \"\"\"\n",
    "    model_path = \"/nfs/speed-scratch/z_amm/COEN490/Koala/ALPR/YOLOv8n_TEST/FSRCNN_x4.pb\"\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    sr.readModel(model_path)\n",
    "    sr.setModel(\"fsrcnn\", 4)  # Use FSRCNN with 4x upscaling\n",
    "    \n",
    "    # Apply super-resolution\n",
    "    upscaled = sr.upsample(image)\n",
    "    return upscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41911d-80ff-4582-b424-4b9becd2aab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117aaa07-29f5-45dd-850a-25d7983d090a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907467d-339c-4bd5-9179-aaaded554a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
